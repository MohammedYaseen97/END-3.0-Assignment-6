{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END3 Session 6 Task 2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammedYaseen97/END-3.0-Assignment-6/blob/main/END3_Session_6_Task_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXEP6oHqcP6x",
        "outputId": "41914a1c-9936-45a4-d2aa-dad8f6494a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "!wget http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\n",
        "\n",
        "data = pd.read_csv(\"quora_duplicate_questions.tsv\", sep='\\t')\n",
        "data.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-27 03:45:36--  http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\n",
            "Resolving qim.fs.quoracdn.net (qim.fs.quoracdn.net)... 151.101.1.2, 151.101.65.2, 151.101.129.2, ...\n",
            "Connecting to qim.fs.quoracdn.net (qim.fs.quoracdn.net)|151.101.1.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58176133 (55M) [text/tab-separated-values]\n",
            "Saving to: ‘quora_duplicate_questions.tsv’\n",
            "\n",
            "quora_duplicate_que 100%[===================>]  55.48M   144MB/s    in 0.4s    \n",
            "\n",
            "2021-11-27 03:45:38 (144 MB/s) - ‘quora_duplicate_questions.tsv’ saved [58176133/58176133]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQzJuvCBfkkX",
        "outputId": "981f9ba7-c4bd-438a-9044-60fbd28d61de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data = data.loc[data['is_duplicate'] == 1]\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>How do I read and find my YouTube comments?</td>\n",
              "      <td>How can I see all my Youtube comments?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>25</td>\n",
              "      <td>26</td>\n",
              "      <td>What can make Physics easy to learn?</td>\n",
              "      <td>How can you make physics easy to learn?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>27</td>\n",
              "      <td>28</td>\n",
              "      <td>What was your first sexual experience like?</td>\n",
              "      <td>What was your first sexual experience?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  qid1  ...                                          question2 is_duplicate\n",
              "5    5    11  ...  I'm a triple Capricorn (Sun, Moon and ascendan...            1\n",
              "7    7    15  ...          What should I do to be a great geologist?            1\n",
              "11  11    23  ...             How can I see all my Youtube comments?            1\n",
              "12  12    25  ...            How can you make physics easy to learn?            1\n",
              "13  13    27  ...             What was your first sexual experience?            1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cghlWWlfvy_",
        "outputId": "20483c45-8de3-4988-87c6-8c0e4d82a1de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data = data.loc[:,['question1', 'question2']]\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How do I read and find my YouTube comments?</td>\n",
              "      <td>How can I see all my Youtube comments?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>What can make Physics easy to learn?</td>\n",
              "      <td>How can you make physics easy to learn?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What was your first sexual experience like?</td>\n",
              "      <td>What was your first sexual experience?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question1                                          question2\n",
              "5   Astrology: I am a Capricorn Sun Cap moon and c...  I'm a triple Capricorn (Sun, Moon and ascendan...\n",
              "7                      How can I be a good geologist?          What should I do to be a great geologist?\n",
              "11        How do I read and find my YouTube comments?             How can I see all my Youtube comments?\n",
              "12               What can make Physics easy to learn?            How can you make physics easy to learn?\n",
              "13        What was your first sexual experience like?             What was your first sexual experience?"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jolV5LUZgAB9",
        "outputId": "1a895e5d-7ec2-4334-ea47-6a7f42d091b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = data.to_numpy().tolist()\n",
        "print(data[0:5])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?', \"I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\"], ['How can I be a good geologist?', 'What should I do to be a great geologist?'], ['How do I read and find my YouTube comments?', 'How can I see all my Youtube comments?'], ['What can make Physics easy to learn?', 'How can you make physics easy to learn?'], ['What was your first sexual experience like?', 'What was your first sexual experience?']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwsY5FiIIK7A"
      },
      "source": [
        "# The architecture we are building\n",
        "\n",
        "![image](https://miro.medium.com/max/1838/1*tXchCn0hBSUau3WO0ViD7w.jpeg)\n",
        "\n",
        "As we can see here, we will have an encoder, an attention mechanism block and decoder. In the final code the attention mechanicm block and decoder will be merged into single block as we need both to work together. \n",
        "\n",
        "As we can see here, we need to create a copy of h1, h2, h3 and h4. These are encoder outputs for a sentence with 4 words. \n",
        "\n",
        "# Encoder\n",
        "\n",
        "We will build our encoder with a GRU, but that's all we know. Let's NOT strait away build a class, but see how to come up with one for the Encoder. We need to answer few questions first:\n",
        "1. what would be the hidden size of our GRU\n",
        "2. What would be the input size\n",
        "3. What would be the embedding dimesions. \n",
        "\n",
        "For simplicity, lets keep 1. and 3. to be 256. \n",
        "\n",
        "We can't feed our input directly to GRU, we need to tensorize it, convert to embeddings first. \n",
        "\n",
        "`embedding = nn.Embedding(input_size, hidden_size) `\n",
        "\n",
        "## What is input_size?\n",
        "\n",
        "Remember the line below?\n",
        "\n",
        "`input_lang, output_lang, pairs = prepareData('eng', 'fra', True)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XswFsPSXQWzy"
      },
      "source": [
        "# 😁\n",
        "\n",
        "Finally our Encoder is fully ready. Now let's look at the class we wrote in the last class to see what we missed!\n",
        "\n",
        "```\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "```\n",
        "\n",
        "Cool! Next let's build out Decoder where we have attention in-built.\n",
        "\n",
        "# Decoder with Attention\n",
        "\n",
        "Here is the plan. \n",
        "\n",
        "1. First input to the decoder will be SOS_token, later inputs would be the words it predicted (unless we implement teacher forcing)\n",
        "2. decoder/GRU's hidden state will be initialized with the encoder's last hidden state\n",
        "3. we will use gru's hidden state and last prediction to generate attention weight using a FC layer. \n",
        "4. this attention weight will be used to weigh the encoder_outputs using batch matric multiplication. This will give us a NEW view on how to look at encoder_states.\n",
        "5. this attention applied encoder_states will then be concatenated with the input, and then sent a linear layer and _then_ sent to the GRU. \n",
        "6. GRU's output will be sent to a FC layer to predict one of the output_language words\n",
        "\n",
        "Let's prepare all the inputs we need to do this\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdDT4RrbYEZx"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMKJsJ3GYH2m"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_2OIu6iYKUt",
        "outputId": "0e514bcb-1f7e-4ccc-cfce-1d4b0da674eb"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-to1tUHYLnx",
        "outputId": "a15acd0b-7333-45f3-fc7e-534062f741f5"
      },
      "source": [
        "!wget http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-26 20:58:42--  http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\n",
            "Resolving qim.fs.quoracdn.net (qim.fs.quoracdn.net)... 151.101.1.2, 151.101.65.2, 151.101.129.2, ...\n",
            "Connecting to qim.fs.quoracdn.net (qim.fs.quoracdn.net)|151.101.1.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58176133 (55M) [text/tab-separated-values]\n",
            "Saving to: ‘quora_duplicate_questions.tsv’\n",
            "\n",
            "quora_duplicate_que 100%[===================>]  55.48M   177MB/s    in 0.3s    \n",
            "\n",
            "2021-11-26 20:58:44 (177 MB/s) - ‘quora_duplicate_questions.tsv’ saved [58176133/58176133]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TeplhycYMWv"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0inG08EYOKf"
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5os4B6QYPZ1"
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    data = pd.read_csv(\"quora_duplicate_questions.tsv\", sep='\\t')\n",
        "    data = data.loc[data['is_duplicate'] == 1]\n",
        "    \n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(pair[0]), normalizeString(pair[1])] for pair in data.loc[::4,['question1', 'question2']].to_numpy().tolist()]   #Taking every 4th entry because it is taking very long to train, and colab is shutting down\n",
        "\n",
        "    # Make Lang instances\n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = input_lang\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg2mGsUGYRI1"
      },
      "source": [
        "MAX_LENGTH = 50\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOYzEWwWYSfj",
        "outputId": "96c4a819-d3b8-4043-b9ea-f5a52fece6be"
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 37316 sentence pairs\n",
            "Trimmed to 37311 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 16873\n",
            "eng 16873\n",
            "['what dog breed would be ideal for a first time owner living in mumbai with a to job ?', 'what dog breed would be ideal for a first time owner living in mumbai ?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq_rtqvzYTgG"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgKx-hHuYspE"
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = F.relu(output)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wadJ6xpyZCF9"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyeUE5oaZG3d"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS8uKk2FZo44"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq0C4hNbZqIm"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uu4NaExZuJ9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8waPFLdZvf7"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud8lBnmqZwbl"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGPbkKkLZxtx",
        "outputId": "8b558893-caef-4ee4-854a-165422e693a8"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1m 12s (- 89m 43s) (1000 1%) 5.0413\n",
            "2m 16s (- 83m 2s) (2000 2%) 4.6494\n",
            "3m 19s (- 79m 49s) (3000 4%) 4.4738\n",
            "4m 22s (- 77m 46s) (4000 5%) 4.4209\n",
            "5m 27s (- 76m 29s) (5000 6%) 4.4025\n",
            "6m 32s (- 75m 14s) (6000 8%) 4.2840\n",
            "7m 36s (- 73m 56s) (7000 9%) 4.2730\n",
            "8m 42s (- 72m 56s) (8000 10%) 4.2413\n",
            "9m 48s (- 71m 53s) (9000 12%) 4.2830\n",
            "10m 53s (- 70m 46s) (10000 13%) 4.1974\n",
            "11m 57s (- 69m 37s) (11000 14%) 4.0598\n",
            "13m 2s (- 68m 28s) (12000 16%) 4.0612\n",
            "14m 7s (- 67m 23s) (13000 17%) 4.1499\n",
            "15m 13s (- 66m 18s) (14000 18%) 4.0152\n",
            "16m 18s (- 65m 14s) (15000 20%) 4.0708\n",
            "17m 22s (- 64m 5s) (16000 21%) 3.9829\n",
            "18m 29s (- 63m 4s) (17000 22%) 4.0372\n",
            "19m 35s (- 62m 2s) (18000 24%) 4.0099\n",
            "20m 41s (- 60m 58s) (19000 25%) 3.9526\n",
            "21m 48s (- 59m 59s) (20000 26%) 4.0086\n",
            "22m 55s (- 58m 57s) (21000 28%) 4.0078\n",
            "24m 1s (- 57m 51s) (22000 29%) 3.9113\n",
            "25m 5s (- 56m 44s) (23000 30%) 3.8990\n",
            "26m 10s (- 55m 36s) (24000 32%) 3.9037\n",
            "27m 15s (- 54m 30s) (25000 33%) 3.9211\n",
            "28m 20s (- 53m 25s) (26000 34%) 3.9246\n",
            "29m 26s (- 52m 20s) (27000 36%) 3.8891\n",
            "30m 32s (- 51m 15s) (28000 37%) 3.9382\n",
            "31m 37s (- 50m 10s) (29000 38%) 3.8879\n",
            "32m 42s (- 49m 4s) (30000 40%) 3.9333\n",
            "33m 47s (- 47m 57s) (31000 41%) 3.9803\n",
            "34m 51s (- 46m 50s) (32000 42%) 3.8085\n",
            "35m 56s (- 45m 44s) (33000 44%) 3.8805\n",
            "36m 59s (- 44m 36s) (34000 45%) 3.8882\n",
            "38m 2s (- 43m 28s) (35000 46%) 3.8266\n",
            "39m 8s (- 42m 24s) (36000 48%) 3.8467\n",
            "40m 14s (- 41m 19s) (37000 49%) 3.9183\n",
            "41m 19s (- 40m 14s) (38000 50%) 3.8632\n",
            "42m 24s (- 39m 9s) (39000 52%) 3.8297\n",
            "43m 30s (- 38m 3s) (40000 53%) 3.7740\n",
            "44m 35s (- 36m 58s) (41000 54%) 3.8112\n",
            "45m 40s (- 35m 53s) (42000 56%) 3.8023\n",
            "46m 44s (- 34m 47s) (43000 57%) 3.8513\n",
            "47m 47s (- 33m 40s) (44000 58%) 3.8959\n",
            "48m 51s (- 32m 34s) (45000 60%) 3.8786\n",
            "49m 55s (- 31m 28s) (46000 61%) 3.8800\n",
            "50m 57s (- 30m 21s) (47000 62%) 3.8853\n",
            "52m 1s (- 29m 15s) (48000 64%) 3.8256\n",
            "53m 5s (- 28m 10s) (49000 65%) 3.8875\n",
            "54m 10s (- 27m 5s) (50000 66%) 3.8826\n",
            "55m 13s (- 25m 59s) (51000 68%) 3.8494\n",
            "56m 18s (- 24m 54s) (52000 69%) 3.8541\n",
            "57m 22s (- 23m 49s) (53000 70%) 3.8211\n",
            "58m 27s (- 22m 44s) (54000 72%) 3.8590\n",
            "59m 31s (- 21m 38s) (55000 73%) 3.8894\n",
            "60m 36s (- 20m 33s) (56000 74%) 3.8859\n",
            "61m 41s (- 19m 28s) (57000 76%) 4.0350\n",
            "62m 44s (- 18m 23s) (58000 77%) 4.6135\n",
            "63m 47s (- 17m 17s) (59000 78%) 4.8616\n",
            "64m 49s (- 16m 12s) (60000 80%) 4.6766\n",
            "65m 51s (- 15m 6s) (61000 81%) 4.6359\n",
            "66m 54s (- 14m 1s) (62000 82%) 4.6169\n",
            "67m 59s (- 12m 56s) (63000 84%) 4.7149\n",
            "69m 3s (- 11m 52s) (64000 85%) 4.6908\n",
            "70m 6s (- 10m 47s) (65000 86%) 4.6323\n",
            "71m 8s (- 9m 42s) (66000 88%) 4.5821\n",
            "72m 11s (- 8m 37s) (67000 89%) 4.5614\n",
            "73m 16s (- 7m 32s) (68000 90%) 4.7105\n",
            "74m 19s (- 6m 27s) (69000 92%) 4.6591\n",
            "75m 22s (- 5m 23s) (70000 93%) 4.6087\n",
            "76m 27s (- 4m 18s) (71000 94%) 4.7862\n",
            "77m 29s (- 3m 13s) (72000 96%) 4.6793\n",
            "78m 32s (- 2m 9s) (73000 97%) 4.6796\n",
            "79m 36s (- 1m 4s) (74000 98%) 4.6634\n",
            "80m 40s (- 0m 0s) (75000 100%) 4.7333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ipQPS5LZy-v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}